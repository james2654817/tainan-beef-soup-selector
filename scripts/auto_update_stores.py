#!/usr/bin/env python3
"""
è‡ªå‹•æ›´æ–°å°å—ç‰›è‚‰æ¹¯åº—å®¶è³‡æ–™
å®šæœŸå¾ Google Maps æœå°‹æ–°åº—å®¶ä¸¦æ›´æ–°ç¾æœ‰è³‡æ–™
"""

import os
import json
import requests
import time
from datetime import datetime
from typing import List, Dict, Set

# å¾ç’°å¢ƒè®Šæ•¸å–å¾— API Key
API_KEY = os.environ.get('GOOGLE_PLACES_API_KEY')

if not API_KEY:
    print("âŒ éŒ¯èª¤ï¼šæœªè¨­å®š GOOGLE_PLACES_API_KEY ç’°å¢ƒè®Šæ•¸")
    exit(1)

# API ç«¯é»
TEXT_SEARCH_URL = "https://maps.googleapis.com/maps/api/place/textsearch/json"
NEARBY_SEARCH_URL = "https://maps.googleapis.com/maps/api/place/nearbysearch/json"
DETAILS_URL = "https://maps.googleapis.com/maps/api/place/details/json"

# å°å—å„å€ä¸­å¿ƒåº§æ¨™
TAINAN_DISTRICTS = {
    'ä¸­è¥¿å€': {'lat': 22.9908, 'lng': 120.2026},
    'æ±å€': {'lat': 22.9856, 'lng': 120.2244},
    'å—å€': {'lat': 22.9583, 'lng': 120.1875},
    'åŒ—å€': {'lat': 23.0108, 'lng': 120.2053},
    'å®‰å¹³å€': {'lat': 23.0011, 'lng': 120.1650},
    'å®‰å—å€': {'lat': 23.0489, 'lng': 120.1864},
    'æ°¸åº·å€': {'lat': 23.0264, 'lng': 120.2571},
    'æ­¸ä»å€': {'lat': 22.9661, 'lng': 120.2933},
}

# æœå°‹é—œéµå­—
SEARCH_KEYWORDS = [
    'ç‰›è‚‰æ¹¯ å°å—',
    'æº«é«”ç‰›è‚‰æ¹¯ å°å—',
    'ç‰›è‚‰åº— å°å—',
]

class StoreUpdater:
    def __init__(self):
        self.existing_stores = {}  # place_id -> store_data
        self.new_stores = []
        self.updated_stores = []
        self.closed_stores = []
        
    def load_existing_data(self, filepath: str):
        """è¼‰å…¥ç¾æœ‰åº—å®¶è³‡æ–™"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                stores = json.load(f)
                for store in stores:
                    self.existing_stores[store['place_id']] = store
            print(f"âœ… è¼‰å…¥ {len(self.existing_stores)} é–“ç¾æœ‰åº—å®¶")
        except FileNotFoundError:
            print("âš ï¸  æœªæ‰¾åˆ°ç¾æœ‰è³‡æ–™ï¼Œå°‡å»ºç«‹æ–°è³‡æ–™åº«")
    
    def search_stores(self) -> Set[str]:
        """æœå°‹æ‰€æœ‰åº—å®¶ï¼Œè¿”å› place_id é›†åˆ"""
        all_place_ids = set()
        
        # 1. é—œéµå­—æœå°‹
        print("\nğŸ“ éšæ®µ 1: é—œéµå­—æœå°‹")
        for keyword in SEARCH_KEYWORDS:
            print(f"ğŸ” æœå°‹: {keyword}")
            place_ids = self._text_search(keyword)
            all_place_ids.update(place_ids)
            time.sleep(1)
        
        print(f"âœ… é—œéµå­—æœå°‹å®Œæˆï¼Œæ‰¾åˆ° {len(all_place_ids)} é–“åº—å®¶")
        
        # 2. å€åŸŸæœå°‹
        print("\nğŸ“ éšæ®µ 2: å€åŸŸæœå°‹")
        for district, location in TAINAN_DISTRICTS.items():
            print(f"ğŸ” æœå°‹ {district}...")
            place_ids = self._nearby_search(location)
            all_place_ids.update(place_ids)
            time.sleep(1)
        
        print(f"âœ… å€åŸŸæœå°‹å®Œæˆï¼Œç¸½å…± {len(all_place_ids)} é–“ä¸é‡è¤‡åº—å®¶")
        
        return all_place_ids
    
    def _text_search(self, query: str) -> Set[str]:
        """æ–‡å­—æœå°‹"""
        place_ids = set()
        next_page_token = None
        
        while True:
            params = {
                'query': query,
                'key': API_KEY,
                'language': 'zh-TW',
                'region': 'tw'
            }
            
            if next_page_token:
                params['pagetoken'] = next_page_token
                time.sleep(2)
            
            try:
                response = requests.get(TEXT_SEARCH_URL, params=params)
                response.raise_for_status()
                data = response.json()
                
                if data['status'] == 'OK':
                    for place in data.get('results', []):
                        place_ids.add(place['place_id'])
                    
                    next_page_token = data.get('next_page_token')
                    if not next_page_token:
                        break
                else:
                    break
            except Exception as e:
                print(f"  âŒ æœå°‹éŒ¯èª¤: {str(e)}")
                break
        
        return place_ids
    
    def _nearby_search(self, location: Dict) -> Set[str]:
        """é™„è¿‘æœå°‹"""
        place_ids = set()
        
        params = {
            'location': f"{location['lat']},{location['lng']}",
            'radius': 5000,
            'keyword': 'ç‰›è‚‰æ¹¯',
            'key': API_KEY,
            'language': 'zh-TW'
        }
        
        try:
            response = requests.get(NEARBY_SEARCH_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            if data['status'] == 'OK':
                for place in data.get('results', []):
                    place_ids.add(place['place_id'])
        except Exception as e:
            print(f"  âŒ æœå°‹éŒ¯èª¤: {str(e)}")
        
        return place_ids
    
    def get_place_details(self, place_id: str) -> Dict:
        """å–å¾—åº—å®¶è©³ç´°è³‡è¨Š"""
        params = {
            'place_id': place_id,
            'key': API_KEY,
            'language': 'zh-TW',
            'fields': 'name,rating,user_ratings_total,formatted_address,formatted_phone_number,opening_hours,reviews,photos,geometry,price_level,types,website,url,business_status'
        }
        
        try:
            response = requests.get(DETAILS_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            if data['status'] == 'OK':
                return data['result']
        except Exception as e:
            print(f"  âŒ å–å¾—è©³ç´°è³‡è¨ŠéŒ¯èª¤: {str(e)}")
        
        return None
    
    def parse_district(self, address: str) -> str:
        """å¾åœ°å€è§£æå€åŸŸ"""
        if not address:
            return None
        
        districts = list(TAINAN_DISTRICTS.keys()) + [
            'æ–°åŒ–å€', 'å·¦é®å€', 'ç‰äº•å€', 'æ¥ è¥¿å€', 'å—åŒ–å€', 'ä»å¾·å€', 'é—œå»Ÿå€',
            'é¾å´å€', 'å®˜ç”°å€', 'éº»è±†å€', 'ä½³é‡Œå€', 'è¥¿æ¸¯å€', 'ä¸ƒè‚¡å€', 'å°‡è»å€',
            'å­¸ç”²å€', 'åŒ—é–€å€', 'æ–°ç‡Ÿå€', 'å¾Œå£å€', 'ç™½æ²³å€', 'æ±å±±å€', 'å…­ç”²å€',
            'ä¸‹ç‡Ÿå€', 'æŸ³ç‡Ÿå€', 'é¹½æ°´å€', 'å–„åŒ–å€', 'å¤§å…§å€', 'å±±ä¸Šå€', 'æ–°å¸‚å€', 'å®‰å®šå€'
        ]
        
        for district in districts:
            if district in address:
                return district
        
        return None
    
    def update_database(self, place_ids: Set[str]):
        """æ›´æ–°è³‡æ–™åº«"""
        print("\nğŸ“ éšæ®µ 3: æ›´æ–°è³‡æ–™åº«")
        
        total = len(place_ids)
        processed = 0
        
        for place_id in place_ids:
            processed += 1
            
            # å–å¾—è©³ç´°è³‡è¨Š
            details = self.get_place_details(place_id)
            if not details:
                continue
            
            # å»ºç«‹åº—å®¶è³‡æ–™
            store_data = {
                'place_id': place_id,
                'name': details.get('name', ''),
                'rating': details.get('rating'),
                'user_ratings_total': details.get('user_ratings_total', 0),
                'address': details.get('formatted_address', ''),
                'phone': details.get('formatted_phone_number', ''),
                'website': details.get('website', ''),
                'url': details.get('url', ''),
                'business_status': details.get('business_status', 'OPERATIONAL'),
                'price_level': details.get('price_level'),
                'types': details.get('types', []),
                'latitude': details.get('geometry', {}).get('location', {}).get('lat'),
                'longitude': details.get('geometry', {}).get('location', {}).get('lng'),
                'opening_hours': details.get('opening_hours', {}),
                'reviews': details.get('reviews', [])[:10],
                'photos': details.get('photos', [])[:10],
                'district': self.parse_district(details.get('formatted_address', '')),
                'updated_at': datetime.now().isoformat()
            }
            
            # åˆ¤æ–·æ˜¯æ–°åº—å®¶é‚„æ˜¯æ›´æ–°
            if place_id in self.existing_stores:
                old_data = self.existing_stores[place_id]
                
                # æª¢æŸ¥æ˜¯å¦æœ‰è®ŠåŒ–
                if (old_data.get('rating') != store_data['rating'] or
                    old_data.get('user_ratings_total') != store_data['user_ratings_total'] or
                    old_data.get('business_status') != store_data['business_status']):
                    
                    self.updated_stores.append({
                        'name': store_data['name'],
                        'changes': {
                            'rating': {'old': old_data.get('rating'), 'new': store_data['rating']},
                            'reviews': {'old': old_data.get('user_ratings_total'), 'new': store_data['user_ratings_total']},
                            'status': {'old': old_data.get('business_status'), 'new': store_data['business_status']}
                        }
                    })
                
                # æ›´æ–°è³‡æ–™
                self.existing_stores[place_id] = store_data
            else:
                # æ–°åº—å®¶
                self.new_stores.append(store_data)
                self.existing_stores[place_id] = store_data
                print(f"  ğŸ†• æ–°åº—å®¶: {store_data['name']}")
            
            # é€²åº¦é¡¯ç¤º
            if processed % 50 == 0:
                print(f"  é€²åº¦: {processed}/{total}")
            
            time.sleep(0.5)
    
    def save_results(self, output_file: str):
        """å„²å­˜çµæœ"""
        all_stores = list(self.existing_stores.values())
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_stores, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… è³‡æ–™å·²å„²å­˜è‡³: {output_file}")
    
    def generate_report(self) -> Dict:
        """ç”Ÿæˆæ›´æ–°å ±å‘Š"""
        return {
            'timestamp': datetime.now().isoformat(),
            'total_stores': len(self.existing_stores),
            'new_stores': len(self.new_stores),
            'updated_stores': len(self.updated_stores),
            'new_store_list': [s['name'] for s in self.new_stores],
            'updated_store_list': self.updated_stores
        }

def main():
    print("="*60)
    print("ğŸ”„ å°å—ç‰›è‚‰æ¹¯åº—å®¶è‡ªå‹•æ›´æ–°")
    print("="*60)
    
    updater = StoreUpdater()
    
    # è¼‰å…¥ç¾æœ‰è³‡æ–™
    data_file = '/home/ubuntu/tainan-beef-soup-selector/scripts/complete_stores_data.json'
    updater.load_existing_data(data_file)
    
    # æœå°‹æ‰€æœ‰åº—å®¶
    place_ids = updater.search_stores()
    
    # æ›´æ–°è³‡æ–™åº«
    updater.update_database(place_ids)
    
    # å„²å­˜çµæœ
    updater.save_results(data_file)
    
    # ç”Ÿæˆå ±å‘Š
    report = updater.generate_report()
    
    # å„²å­˜å ±å‘Š
    report_file = f'/home/ubuntu/tainan-beef-soup-selector/scripts/update_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # é¡¯ç¤ºæ‘˜è¦
    print("\n" + "="*60)
    print("âœ… æ›´æ–°å®Œæˆï¼")
    print("="*60)
    print(f"ç¸½åº—å®¶æ•¸: {report['total_stores']}")
    print(f"æ–°å¢åº—å®¶: {report['new_stores']}")
    print(f"æ›´æ–°åº—å®¶: {report['updated_stores']}")
    print(f"\nå ±å‘Šå·²å„²å­˜è‡³: {report_file}")

if __name__ == "__main__":
    main()

